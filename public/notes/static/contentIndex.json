{"Templater":{"slug":"Templater","filePath":"Templater.md","title":"Templater","links":["Templater"],"tags":["obsidian"],"content":"Templater is an Obsidian extension that can be used to automate the creation of notes and automatically sort them based on prompts. i use it extensively to quickly create literature notes.\nsystem prompts with Templater\nwhen using the templater extension, you can add prompts to create variables that can used in the created note. so when you make a new note using templater, a modal will pop up asking you for the desired variable. this can save a lot of time if a certain variable is used in multiple places throughout a note. to add prompts, use the const variableName = await tp.system.prompt(&quot;Variable Name&quot;) to the top of the template. here’s an example i use in my TV episode template.\n&lt;%*\nconst seriesName = await tp.system.prompt(&quot;Series Name&quot;)\nconst episodeNumber = await tp.system.prompt(&quot;Episode Number&quot;)\nconst URL = await tp.system.prompt(&quot;URL&quot;)\nconst publishDate = await tp.system.prompt(&quot;Published Date (YYYY-MM-DD)&quot;)\n%&gt;\nautomatically sort notes with Templater\nyou can automatically move a note when creating it with the templater plugin using tp.file.move. here’s a simple example, where title is a variable created with a system prompt.\n&lt;%*\t\n\tawait tp.file.move(&quot;/desired folder/&quot; + title)\n%&gt;\nyou can even automatically create folders using already created variables. for example, this is part of the code in my TV episode template. it automatically renames the note to “Episode {episodeNumber}” and moves it into a folder with the series name, creating the folder if it doesn’t exist already.\n&lt;%*\n// rename file\ntitleName = &quot;Episode &quot; + episodeNumber;\nawait tp.file.rename(titleName);\n \n// make the directory a folder with the name of the series inside the tv show literature note folder\nconst dir = &quot;/020 literature notes/tv/&quot; + seriesName;\n \n// if directory doesn&#039;t exist\nif (!tp.file.exists(dir)) {\n\t// create the folder\n\tawait this.app.vault.createFolder(dir);\n}\n \n// move current note to the series folder\nawait tp.file.move(dir + &quot;/&quot; + titleName, tp.file.find_tfile(titleName))\n%&gt;\ncreating another note using Templater\nyou can use the function tp.file.create_new inside of a template to create an additional file when creating a file using templater. when i make a literature note, i use it to automatically create another note that lists every note from that source. for example, if i make a note for a TV episode, the following code will check if a note with the series name already exists. if not, it creates another note using the template TV Series Template and automatically sorts it into the folder with my episode notes (the variables .\n// check if a note with the series name exists\nconst existing = tp.file.find_tfile(seriesName);\n \n// if it doesn&#039;t exist\nif (!existing) {\n\t\n\t// get the series template file content\n\tconst templateName = &quot;TV Series Template&quot;\n\tlet templateFile = await tp.file.find_tfile(templateName);\n\tlet templateContent = await app.vault.read(templateFile);\n\t\n\t// create series note\n\tawait tp.file.create_new(templateContent, seriesName, false, dir);\n}\nthe note for the series uses dataview to display a table of all the episodes i’ve already taken notes on (replace the “ with ```)\n---\ncategory: tv\ntype: series\nseries: &quot;&lt;% tp.file.title %&gt;&quot;\ntags: format/tv, type/series \n---\n# &lt;% tp.file.title %&gt;\n \n``dataview\n\ttable published as &quot;Date Aired&quot;\n\twhere show = &quot;&lt;% tp.file.title %&gt;&quot;\n\tsort file asc\n``\n \n---\n[[TV Shows]]"},"configuring-yomitan-for-thai":{"slug":"configuring-yomitan-for-thai","filePath":"configuring yomitan for thai.md","title":"configuring yomitan for thai","links":[],"tags":["language_learning/thai"],"content":"dictionaries\nthe dictionaries i use are:\n\nkaikki th-th and th-en\napple th-en\nJTDIC th-jp\nLexitron th-en\nvolubilis th-en\nroyal institute dictionary th-th\nIsan-Thai-English dictionary th-th-en\nplant names th-en\npleang na nakoen th-th\njones th-en\nabbreviations th-th\n\nthe unlinked dictionaries were sourced from thai dictionaries project and converted using pyglossary. you can download all these dictionaries in one file here. to import, go to the settings page of yomitan, scroll down to “backup”, click “import dictionary collection”, then select the json file downloaded earlier. to enable them, scroll up to “dictionaries” then click on “configure installed and enabled dictionaries…”. enable all of them. i recommend putting the kaikki dictionaries on top since they have the best coverage and nicest formatting imo.\nyomitan settings\n\nin “general”, set language to thai.\nin “appearance”, set the font to something that’s compatible with thai (i prefer ibm plex sans thai). i recommend setting the font size and line height bigger, like 24px and 1.5. click “configure custom css” then add this under “popup css” to make the head word less big when increasing the font size.\n\n:root {\n--headword-font-size-no-units: 1.75;\n}\n \n.actions {\nfont-size: 16px;\n}\n\nin “popup position and size”, i recommend increasing the size if you increased the font. i use 650x600px.\nin “audio”, enable languagepod101. you can also get forvo audio using this anki extension.\nin “translation”, click “configure custom text replacement patterns”. add the following replacements:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatternreplacement(.)ํา$1ำ\\s"},"goldendict":{"slug":"goldendict","filePath":"goldendict.md","title":"goldendict","links":["ocr"],"tags":["language_learning"],"content":"goldendict-ng is a program for windows, mac, and linux that allows the user to install their own dictionaries to look up words instantly. even though i mainly use yomitan to look words up in a browser, i still find it handy to have another dictionary service to fall back on when i want to looking something up outside of my browser.\ni highly recommend reading tatsumoto’s guide on setting up goldendict. the following are my personal preferences and some recommendations for using it with thai.\ndictionaries\ninstall dictionaries by opening goldendict, clicking “edit” &gt; “dictionaries…” then under “sources” &gt; “files” add the folder that has all the dictionaries you’ve downloaded. if you want go to “wikipedia” and add the wikitionary of your target language (i recommend adding thai if you’re studying it). if you’re studying multiple languages i recommend clicking on “groups” and sorting your dictionaries based on target language.\na huge repository of dictionaries for many languages can be found here.\nthai\ni recommend installing the dictionaries from thai dictionaries project except use this version of the volubilis dictionary. at the very least i would add\n\nRoyal Institute Thai - Thai Dictionary (modified version)\nIsan Thai - Thai - English Dictionary (Dr. Preecha Phinthong)\nPleang Na Nakorn dictionary\nThai - English LEXiTRON dictionary v. 2\nthe version of the volubilis dictionary linked above\n\nyou can download thai hunspell files here.\njapanese\njitendex is available for goldendict. i also like kenkyusha new japanese-english dictionary, kireicake, and a dictionary of japanese grammar, all of which can be downloaded here.\nkeyboard shortcuts\nwhile goldendict can show a little popup icon on selection changes that you can click to send the selection to goldendict, this feature is broken on wayland. on linux, i bind SUPER+C to run the following script:\n#!/bin/bash\n \n# strip clipboard of all whitespace\nclipboard=$(wl-paste | tr -d &#039;[:space:]&#039;)\n \n# open clipboard in goldendict\ngoldendict-ng $clipboard\non x11, change wl-paste with xclip. i find stripping the whitespace helpful when reading a pdf that’s been ocr’d, since i find ocrmypdf often adds whitespace characters inside of words to keep the location of the invisible text layer in the same spot as the original document.\ngoldendict also supports clipboard monitoring i.e. every time you copy something the goldendict window will pop up with a translation for whatever was copied. i usually recommend having it off, then turning it on when reading manga, playing games, etc where you use ocr tools that send the output to the clipboard to expedite the word lookup process.\ncustom styling: multiple font support\nto add support for multiple custom fonts, open the configuration folder (~/.goldendict on my machine, or open goldendict, click on help, then click on configuration folder). create a file called article-style.css. here’s my custom styling to add support for thai and japanese.\nbody,\n.ipa,\n.phon,\n.phone,\n.pron,\n.audio-gb,\n.audio-us {\n\tfont-family: &quot;IBM Plex Sans Thai Looped Light&quot;, &quot;IBM Plex Sans JP&quot;!important;\n\tfont-size:16px!important;\n}"},"hiding-hard-subtitles":{"slug":"hiding-hard-subtitles","filePath":"hiding hard subtitles.md","title":"hiding hard subtitles","links":[],"tags":["language_learning","linux"],"content":"i use the python program subtitle hider to blur english subtitles hardcoded into videos i want to watch in a language i’m learning. under “releases” there’s also a precompiled windows .exe. since it creates a new window, it’s compatible with any video player app, website, etc.\nin hyprland, i use the following settings to launch the program with a keybind using my preferred settings and location. (the title has been changed from main.py to subtitle_hider.py and saved in ~/scripts)\nin my window rules configuration:\nwindowrule = float, title:subtitle_hider.py\nwindowrule = opacity 0.3 override 0.5 override, title:subtitle_hider.py\nwindowrule = xray 0, title:subtitle_hider.py\nwindowrule = noshadow, title:subtitle_hider.py\nwindowrule = noborder, title:subtitle_hider.py\nwindowrule = noblur, focus:1,title:subtitle_hider.py\nwindowrule = move onscreen 11% 71%, title:subtitle_hider.py\nwindowrule = size 78% 6%, title:subtitle_hider.py \nin my user binds configuration:\nbind = $mainMod SHIFT, H, exec, python $HOME/scripts/subtitle_hider.py # launch window that blurs part of the screen (for hiding hard subs)\nthis is what it looks like in action. you can see that on hover the blur effect is turned off and it can be freely moved and resized. the color of the window can be set to white, black, or transparent (blur only).\n\nvideo: บุกญี่ปุ่น หลัง Lost Decades เศรษฐกิจหลุดเงามืดแล้ว จริงหรือไม่ ? | INSIGHTS ON JAPAN ECONOMY EP.1 - YouTube\nprogram to show keystrokes: GitHub - AlynxZhou/showmethekey: Show keys you typed on screen."},"index":{"slug":"index","filePath":"index.md","title":"welcome to my notebook","links":["tags/language_learning","tags/site_building","tags/linux"],"tags":["language_learning","site_building","linux"],"content":"this section of my site is a repository of random notes mostly related to language_learning , site_building , and linux . i’m pretty bad at remember how i did things or the exact names of commands, so i end up documenting everything i do so i can replicate things later. most of the improvements and optimizations i’ve made to my site were made after coming across blog posts and coding tip sections on random peoples sites, and i’ve found reading other people’s documentation of their own workflow to be extremely helpful in learning how to use tools like eleventy and deploy to neocities, so i thought i ought to pay it back and learn in public for anyone who may stumble across my own website."},"normalizing-audio":{"slug":"normalizing-audio","filePath":"normalizing audio.md","title":"normalizing audio","links":["updating-ffmpeg"],"tags":["language_learning","linux"],"content":"i use ffmpeg to normalize the audio of my media files, particularly anything i want to sentence mine. i also like to normalize my anki media folder every month or so. be sure you’re on an up-to-date build of ffmpeg to use the following methods. (see updating ffmpeg for how i updated ffmpeg on pop os, which should work on other debian based distributions)\nbatch normalize audio files\nto batch normalize audio files, install ffmpeg-normalize using pip install ffmpeg-normalize. inside the folder, run”\nffmpeg-normalize *.mp3 -c:a libmp3lame -ext mp3 -pr\nmp3gain can be used change gain without the need to reencode the track. i like to use this in my anki media folder since it is much faster than ffmpeg-normalize. the link has downloads for windows, but on linux it can be installed from your distro’s repository. to run from the command line:\nmp3gain -r -k -s r *.mp3\nnormalize video audio\nfor a single video:\nffmpeg -i infile.mp4 -filter:a speechnorm,loudnorm -c:a ac3 -c:v copy out.mp4 \nto run the above command on a whole folder in linux or mac, use:\nfor i in *.mkv; do ffmpeg -i &quot;$i&quot; -filter:a speechnorm,loudnorm -c:a ac3 -c:v copy &quot;normalized/$i&quot;; done\nor\nffmpeg-normalize *.mkv -c:a ac3 --dynamic --progress\nthe normalized videos will have the same name but will be in the subfolder titled “normalized”"},"ocr":{"slug":"ocr","filePath":"ocr.md","title":"ocr","links":["goldendict"],"tags":["language_learning","linux"],"content":"the following are the programs and scripts i use to make looking up words easier when reading manga, webtoons, or books in pdf format.\nscreenshots (for cartoons)\ni mainly use two methods for ocr: the pot app and huggingface spaces through api. pot defaults to using the ocr built into the system (for linux, tesseract) which doesn’t require internet but takes up more space on your computer and can be slow on older hardware. it also supports using online ocr services. using a huggingface space through api requires internet access and some scripting knowledge but some of the models are more fine-tuned for certain types of text, producing better results. if you don’t want to use the api, they can still be used it the browser by uploading a screenshot.\nwhen i was using windows i used capture2text which also uses tesseract to ocr images and supports keybinds + sending to clipboard which can be combined with goldendict’s or yomitan’s clipboard monitoring to make lookups fast.\npot\nafter installing pot, its icon should appear in the system tray. then simply click on the icon, click “ocr recognize”, select the region, and a window should pop with the text extracted. the ocr engine and language can be changed from here. if auto copy is turned on in the settings and goldendict clipboard monitoring is turned on, then words can be looked up from manga, cartoons, etc in a few clicks from any application.\non wayland, selecting “ocr recognize” from the app currently doesn’t work. i bind the following script to SUPER+S to use pot:\n#!/bin/bash\n \n# check if pot is running\nif ! pidof pot\nthen\n\t# open pot first\n\t~/Applications/pot.appimage &amp;\nfi\n \n# remove old screenshot\nrm ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png\n \n# open screenshot gui\ngrimblast --notify save area ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png\n \n# open screenshot in pot\ncurl &quot;127.0.0.1:60828/ocr_recognize?screenshot=false&quot;\nif not using hyprland, change the grimblast line with flameshot gui -s -p ~/.cache/com.pot-app.desktop/pot_screenshot_cut.png to use flameshot, or replace it with the screenshot tool of your choice.\nhuggingface spaces\nat the bottom of most huggingface spaces, there should be link on how to use the space via api with bash, python, and javascript. i mainly use the Thai OCR with TrOCR space since it seems to work much better than pot + tesseract for handwritten-type fonts common in manga and manhwa. this is the python script i use with that space. it takes a screenshot of an area of the screen using grimblast, sends the image to the huggingface space to be processed, returns the output as a string, and sends the string to goldendict:\n#!/usr/bin/env python\n \nfrom gradio_client import Client, handle_file\nimport subprocess\n \n# remove old screenshot\nsubprocess.run([&quot;rm&quot;, &quot;/home/balfiere/Pictures/Screenshots/thaiOCR.png&quot;]) \n \n# take screenshot\nsubprocess.run([&quot;grimblast&quot;, &quot;--notify&quot;, &quot;save&quot;, &quot;area&quot;, &quot;/home/balfiere/Pictures/Screenshots/thaiOCR.png&quot;])\n \n# run ocr in huggingface space: huggingface.co/spaces/phoner45/thai-ocr-img\n# works best if text only spans one line\nclient = Client(&quot;phoner45/thai-ocr-img&quot;)\nresult = client.predict(\n\t\timage=handle_file(&#039;/home/balfiere/Pictures/Screenshots/thaiOCR.png&#039;),\n\t\tapi_name=&quot;/predict&quot;\n)\n \n# open ocr result in goldendict-ng\nsubprocess.run([&quot;goldendict-ng&quot;, result])\nin hyprland i have bind = $mainMod SHIFT, S, exec, python ~/scripts/thaiTrOCR.py added to my keybind configuration file so that i can ocr an image and get a definition to pop up all with a single keystroke.\nwhole documents (for books)\nremoving watermarks\nwhen i checkout ebooks from tk park, they put a watermark over every page of the book which can mess with ocr results. to remove a simple gray watermark from a black and white book, in a folder of images where each image is a page use\nmkdir converted\nfor f in  *.png; do magick &quot;$f&quot; -sigmoidal-contrast 21,57% converted/&quot;$f&quot; ; done\nto remove the watermark. it has better results with anti-aliasing around words vs replacing color directly, but you can still fall back on direct color replacement + fuzz:\nfor f in  *.png; do magick &quot;$f&quot; -fuzz 15% -fill white -opaque &#039;#DEDFE0&#039; converted/&quot;$f&quot; ; done\npdf\nentire pdfs can be ocr’d using ocrmypdf on linux, windows, and mac. in the directory with the pdf, type ocrmypdf &#039;my input pdf.pdf&#039; &#039;my output pdf.pdf&#039; -l eng. uses tesseract to ocr. can use -c to clean the pages before scanning, and -i to incorporate the cleaning into the final pdf. the selectable text is applied as an invisible layer on top of the pdf and can be extracted as a separate text file using the sidecar option.\nthe following is an example that cleans and deskews in.pdf, ocr’s pages 3 through 326 in thai, produces a text file output.txt with only the ocr’d text, and applies the maximum amount of compression to the output file ocr.pdf.\nocrmypdf -l tha --clean --deskew --optimize 3 --pages 3-326 --sidecar output.txt --pdf-renderer=sandwich in.pdf ocr.pdf\nimage to pdf\nif you have a folder of images that you want to turn into a pdf first, here are two methods:\n# fast\nimg2pdf *.png -o processed.pdf\n \n# imagemagick only\nmagick *.png -quality 100 processed.pdf\nthai only: python_thai_ocr\ni typically prefer using python_thai_ocr over ocrmypdf, i find it gives more accurate results (even though they both use tesseract… idk what’s up with that). the github page has instructions on how to use it, but i find that it often crashes and uses tons of cpu power when running on pdfs compared to images. to bypass the issue, i instead turn the pdf into a folder of images (if they aren’t already just images) and simply run a script that processes each image individually, appending the output of each page to a text file:\n#!/bin/bash\n \n# first argument is the output file\noutput=$1\n \n# remove the output file if it already exists\nrm -f &quot;$output&quot;\n \n# create the output file\ntouch &quot;$output&quot;\n \n# page counter\ni=0\n \n# process each image in the current directory\nshopt -s nocaseglob\nshopt -s nullglob\nfor f in *.{jpg,jpeg,tiff,bmp,png}\ndo\n    # increase the page counter\n    i=$((i+1))\n \n    # process the image and save output to temporary file\n    # uses github.com/nanonymoussu/python_thai_ocr\n    python $HOME/python_thai_ocr/main.py &quot;$f&quot; temp\n \n    # add page header\n    echo -e &quot;✧˖°─ .✦──── ･ ｡ﾟ⟡ ☽ Page ${i} ☾ ⟡ ˚｡ ･ ────✦.─ °˖✧\\n&quot; | cat &gt;&gt; &quot;$output&quot; # cute version (more at emojicombos.com/divider)\n    # echo -e &quot;===============Page ${i}===============\\n&quot;  | cat &gt;&gt; &quot;$output&quot; # boring version\n \n    # add page content\n    cat temp &gt;&gt; &quot;$output&quot;\n \n    # add empty lines at end of page\n    echo -e &quot;\\n\\n&quot; | cat &gt;&gt; &quot;$output&quot;\n \ndone\n \n# remove temporary file\nrm temp\nif the script is saved to ~/scripts/thai_images2ocr then it can be run by moving the working directory to the folder with the images and running ~/scripts/thai_images2ocr ocr.txt ."},"texthooking-games-in-linux":{"slug":"texthooking-games-in-linux","filePath":"texthooking games in linux.md","title":"texthooking games in linux","links":[],"tags":["language_learning","linux"],"content":"installing games\nwhere to download\n\ncs rin ru (if on steam)\nRuTracker.org (lots of old, hard to find games on here. definitely check here for otome games)\nBrowse :: Nyaa (if no h content)\nBrowse :: Sukebei (if h content. sometimes games without h content are still posted here tho)\nDeso Novel (mostly eroge but has some non-eroge. most older links are down)\n\ninstalling old region locked games\nto install games, set up a prefix according to Visual novels on Linux - TheMoeWay. if using PortProton to launch games, move the prefix to\n~/.var/app/ru.linux_gaming.PortProton/prefixes/VNS\n\notherwise PortProton will not be able to run the game in the created prefix.\nif game needs to be installed (not a portable game), install using lutris in the above prefix. games that require the CD to be mounted or need to be installed from CD can use CDemu to mount the iso/mds.\ni also like to install LAVFilters into this prefix, which can be installed using winetricks. if using PortProton, open PortProton, click on “Wine Settings”, set prefix to “VNS” and wine to your favorite version of wine (mine is GE-PROTON9-27) then click “Winetricks”. scroll down and select library “lavfilters702”, then click “Install”.\nother guides for setting up wine prefixes for visual novels (has more info on getting video playback working):\n\nSetting up a wine prefix for visual novels with movie playback support (guide)\nPlaying visual novels on GNU/Linux with Wine - Friendly GNU/Linux Thread/Website\n\nrunning games\nPortProton\ni mainly use PortProton to manage my prefixes, per-game settings, and launching games with proton. i find it a bit easier to tweak settings and change proton versions compared to lutris or steam.\nto force japanese local: at the game menu, click “Settings” &gt; “Base settings” &gt; “Advanced”. next to “Force certain locale for an app:” select “ja_JP.utf”\nmost games can be run using the all-purpose “VNS” prefix with some form of Proton-GE. i usually test games with the latest version, 9-27, then normal wine (they start with WINE-LG if downloading though PortProton) before creating a separate prefix to troubleshoot the issue, then stick with the same proton version until finishing the game.\nonce the game starts, the portproton icon will appear in the system tray. the .exe of the text hooker of choice can be started from either “winefile” or “taskmgr”.\nother launchers\nif using lutris, read this section of TheMoeWay guide linked above on how to add installed games to lutris and this section on how to get your texthooker of choice to launch automatically.\ni like to use cartridges to manage all of my games (not just visual novels). to add a game manually, can use xdg-open or gio open with a link to the game .exe to open in the default app for launching .exe files. you can also launch the game with your distro’s installed version of wine in a specific prefix using the wine command:\nWINEPREFIX=&quot;~/.var/app/ru.linux_gaming.PortProton/prefixes/DEFAULT&quot; wine &#039;~/Games/Folder/GameName.exe&#039;\ngames crashing\nsometimes games will crash if a prefix is missing the necessary codec to play video in game. information on what codec is necessary for a given game may be posted at protondb if the game is on steam or this archived compatibility list from visualnovelwiki.\ncodecs can be installed through winetricks or vn_winestuff. more info on how to use the script can be found here. an example for use with a prefix made by PortProton:\ngit clone github.com/b-fission/vn_winestuff.git\ncd vn_winestuff\nWINEPREFIX=~/.var/app/ru.linux_gaming.PortProton/prefixes/TEST ./codec.sh wmp11 quartz2\nforce use of dGPU\nmost visual novels are openGL and will default to running on iGPU. if launching game through PortProton, can force openGL games to run on dGPU byt clicking “Settings” &gt; “Base settings” and turning on “Use Native Wayland”. if opening directly from the command line or another game manager, add __NV_PRIME_RENDER_OFFLOAD=1 __GLX_VENDOR_LIBRARY_NAME=nvidia to the front of the command.\ntexthooking\ntexthookers\nmy preferred texthookers in order are agent &gt; lunahook &gt; lunatranslator.\nagent\nagent uses javascript to hook games. while most texthookers can only hook visual novels, agent can hook a wider range of games so long as a script for the game has been written.\nwhile other texthookers only support windows, the linux version of agent can be used with yuzu to hook emulated switch games. agent can only be used with certain builds of emulators, which can be found here. so far i haven’t had luck with getting the linux version of agent to hook the linux versions of vita3k and pcsx2. if hooking a windows game or emulator, need to run the windows version of agent.\nlunahook\nlunahook is just the texthooking part of the larger lunatranslator program. it is meant to replace the no longer developed program textractor. the lunatranslator developer no longer builds lunahook separately, but version 5.0.0 can be found here and version 6.3.3 can be found here (use the Release_English version, the regular Release version crashes for me). be sure to download the plugins too. most games are 32-bit so you’ll usually use LunaHost32.exe, but some games (like games built with ren’py) are 64-bit.\nlunahook automatically finds potential hooks based on the engine the game was written in. if the right hook isn’t found, you can make it search for a hook manually by typing the text currently on the screen or starting the search, advancing the text, and letting lunahook search for potential addresses the text info could be stored.\nlunatranslator\nlunatranslator can texthook games as well as use ocr. i find it prone to crashing when running through wine, so i reach for it last. it has a feature where you can set it to ocr part of the screen and rescan automatically based on button presses or screen change. i mainly use this with old emulated games that use non-standard text encoding, as hooking them isn’t as straightforward as games that use a standard encoding. the ocr feature works with any part of the screen, so it can be used with an emulated game running in linux.\nsteam games\nsince steam games are installed into their own prefix, and texthookers need to run in the same instance as the game, need to use special tools to run other programs at same time as launching a game from steam.\nfor detailed instructions on how to launch a text hooker with a steam game (works with texthookers that aren’t agent as well): LINUX GUIDE How to use text hooker (Agent) with Steam Flatpak\ntldr: after installing SteamTinkerLauncher, open properties &gt; compatibility then set the compatibility tool to Steam Tinker Launcher. open the game, click main menu, click game menu, click misc options, then set the desired text hooker as a custom command and click fork custom command.\nmay need to add font files to game prefix at drive_c/windows/Fonts.\nHcodes\nif unable to hook automatically, agent and textractor support using Hcodes. can be found from the following sources:\n\nH-Code | Visual Novel Text Hooking Wiki | Fandom\nJapanese Visual Novel Hook Codes.pdf - Google Drive\nsometimes people post hcodes in the discussion section of a game’s vndb page\n\nfiltering text\nusing lunahook or textractor, can use the plugin ‘Regex Filter’ to remove unwanted characters. examples:\n\n\\s (filters all whitespace)\n[\\u0021-\\u00ff] (filters all european language and most special characters)\n[\\u0100-\\uffff] (filters all non european language characters)\n[\\u0000-\\u2fff\\ua000-\\uffff] (filters all non Chinese/Japanese/Korean characters)\n&lt;.+?&gt; (filters all HTML tags like &lt;p id=&quot;some_guid&quot;&gt; or &lt;/span&gt;)\n\nFAQ · Artikash/Textractor Wiki · GitHub"},"updating-ffmpeg":{"slug":"updating-ffmpeg","filePath":"updating ffmpeg.md","title":"updating ffmpeg","links":["video-to-avif","normalizing-audio"],"tags":["linux"],"content":"the version of ffmpeg that comes installed on pop os 22.04 is version 4.4.2, which doesn’t come with libsvtav1 to make avif files and doesn’t work well with ffmpeg-normalize. i followed this tutorial to install it but got the version here. also see another av1 encoding tutorial here.\nsudo apt remove ffmpeg\nsudo mkdir -p /opt/ffmpeg\ncd /opt/ffmpeg\nsudo wget github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz\nsudo tar xvf ffmpeg-master-latest-linux64-gpl.tar.xz\ncd ffmpeg-*-gpl/bin/\nsudo ln -s &quot;${PWD}/ffmpeg&quot; /usr/bin/\nsudo ln -s &quot;${PWD}/ffprobe&quot; /usr/bin/\nsudo ln -s &quot;${PWD}/ffplay&quot; /usr/bin/"},"video-to-avif":{"slug":"video-to-avif","filePath":"video to avif.md","title":"video to avif","links":["places","updating-ffmpeg"],"tags":["site_building"],"content":"i use avif files on my site wherever i want to convert a video to an animated image. avif files are significantly smaller than gifs while retaining much more quality, have pretty good support on modern browsers, can be used with the img html tag, and are able to be hosted on neocities even on free accounts. the backgrounds for my places page, for example, use avif but fall back to jpg if avif isn’t supported.\nthe following method requires a version of ffmpeg which has the libsvtav1 encoder library, which should be ffmpeg versions newer than 5.1.0. see updating ffmpeg for a link to the ffmpeg build i use (includes builds for windows and linux) as well as how to update ffmpeg on pop os and other debian based distros. you can also use ezgif.com to convert videos to avif. ezgif also supports converting gifs to avif, but if you have the original video file i would highly suggesting using that as the step from video to gif introduces a lot of extra noise, which if you then convert to avif would lead to a larger image size and worse quality than if you had converted the video straight to avif. if you color your gifs in photoshop, you can export to mp4 instead of gif.\nbasic command\nffmpeg -hide_banner -i &quot;input.mkv&quot; -c:v libsvtav1 &quot;output.avif&quot;\nan example with time trimming and scaling\nffmpeg -hide_banner -ss 11.736986301369864 -to 24.095362 -i &quot;input.mp4&quot; -vf &quot;scale=640:-2&quot; -c:v libsvtav1 &quot;output.avif&quot;\nan example with time trimming, cropping, scaling, and extra compression\nffmpeg -hide_banner -ss 00:00:26 -to 00:00:53 -i input.mp4 -vf &quot;crop=in_w-4:in_h-22:2:0,scale=850:-2&quot; -c:v libsvtav1 -crf 40 -preset 6 &quot;output.avif&quot;\nbatch convert\nwindows\nwhen i used windows i kept the following in a .ps1 file\nforeach ($f in gci *.mp4) { ffmpeg -hide_banner -i $f -c:v libsvtav1 &quot;$($f.basename).avif&quot; }\nlinux\nfor f in *.mp4; do ffmpeg -i &quot;$f&quot; -c:v libsvtav1 &quot;$(&quot;$f&quot;.basename).avif&quot;; done"}}